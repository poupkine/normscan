import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import os
import logging
import random
from pathlib import Path
from tqdm import tqdm
from src.dataloader.dicom_loader import load_dicom_from_zip
from src.model.autoencoder_2d import UNet2D  # ‚Üê –ù–û–í–ê–Ø 2D –ú–û–î–ï–õ–¨
import pydicom  # ‚Üê ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –ò–ú–ü–û–†–¢ –î–õ–Ø isinstance(slope, pydicom.valuerep.DSfloat)


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É models/, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç ‚Äî –ö–†–ò–¢–ò–ß–ù–û!
os.makedirs(os.path.dirname("models/autoencoder_2d.pth"), exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 32
NUM_EPOCHS = 10
LEARNING_RATE = 5e-5
SAVE_PATH = "models/autoencoder_2d.pth"


class CTNormalDataset(Dataset):
    def __init__(self, zip_files):
        self.zip_files = zip_files
        self.all_slices = []  # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å—Ä–µ–∑–æ–≤ —Å–æ –≤—Å–µ—Ö ZIP-—Ñ–∞–π–ª–æ–≤

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º ZIP-—Ñ–∞–π–ª–∞–º –∏ —Å–æ–±–∏—Ä–∞–µ–º –í–°–ï —Å—Ä–µ–∑—ã
        for zip_path in zip_files:
            dicom_list = load_dicom_from_zip(zip_path)
            for ds in dicom_list:
                if hasattr(ds, 'pixel_array') and ds.pixel_array is not None:
                    self.all_slices.append((zip_path, ds))

        logger.info(f"–°–æ–±—Ä–∞–Ω–æ {len(self.all_slices)} —Å—Ä–µ–∑–æ–≤ –∏–∑ {len(zip_files)} ZIP-—Ñ–∞–π–ª–æ–≤.")

    def __len__(self):
        return len(self.all_slices)

    def __getitem__(self, idx):
        zip_path, ds = self.all_slices[idx]

        # –ü–æ–ª—É—á–∞–µ–º –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        pixel_array = ds.pixel_array.astype(np.float32)

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ HU
        slope = getattr(ds, 'RescaleSlope', 1.0)
        intercept = getattr(ds, 'RescaleIntercept', 0.0)
        if isinstance(slope, pydicom.valuerep.DSfloat):
            slope = float(slope)
        if isinstance(intercept, pydicom.valuerep.DSfloat):
            intercept = float(intercept)
        hu_image = pixel_array * slope + intercept

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ HU
        hu_image = np.clip(hu_image, -1000, 400)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ [0, 1]
        min_val, max_val = hu_image.min(), hu_image.max()
        if max_val == min_val:
            slice_norm = np.zeros_like(hu_image)
        else:
            slice_norm = (hu_image - min_val) / (max_val - min_val)

        # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –¥–æ 128x128
        from scipy.ndimage import zoom
        h, w = slice_norm.shape
        zoom_factors = (128 / h, 128 / w)
        slice_resized = zoom(slice_norm, zoom_factors, order=1, prefilter=False)

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª: (128, 128) ‚Üí (1, 128, 128)
        tensor = torch.tensor(slice_resized, dtype=torch.float32).unsqueeze(0)

        # üî• –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–ò ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è –æ–±–æ–±—â–µ–Ω–∏—è
        if random.random() > 0.5:
            noise = torch.randn_like(tensor) * 0.01
            tensor += noise
            tensor = torch.clamp(tensor, 0, 1)

        if random.random() > 0.5:
            shift = random.randint(-8, 8)
            tensor = torch.roll(tensor, shifts=shift, dims=1)
            tensor = torch.roll(tensor, shifts=shift, dims=2)

        return tensor


def train_autoencoder():
    zip_files = list(Path("data/train_normal").glob("*.zip"))
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(zip_files)} ZIP-—Ñ–∞–π–ª–æ–≤ —Å –Ω–æ—Ä–º–æ–π.")

    if len(zip_files) == 0:
        raise FileNotFoundError(
            "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ data/train_normal/. –ü–æ–º–µ—Å—Ç–∏—Ç–µ ZIP-—Ñ–∞–π–ª—ã —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –ö–¢-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º–∏ (–±–µ–∑ –ø–∞—Ç–æ–ª–æ–≥–∏–π)!"
        )

    dataset = CTNormalDataset(zip_files)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)

    model = UNet2D(in_channels=1, out_channels=1, base_features=32).to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    logger.info("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
    for epoch in range(NUM_EPOCHS):
        model.train()
        total_loss = 0.0
        pbar = tqdm(dataloader, desc=f"Epoch {epoch + 1}/{NUM_EPOCHS}")

        for batch in pbar:
            batch = batch.to(DEVICE)
            optimizer.zero_grad()
            recon = model(batch)
            loss = criterion(recon, batch)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            pbar.set_postfix({"loss": f"{loss.item():.6f}"})

        avg_loss = total_loss / len(dataloader)
        logger.info(f"Epoch [{epoch + 1}/{NUM_EPOCHS}], Avg Loss: {avg_loss:.6f}")
        torch.save(model.state_dict(), SAVE_PATH)
        logger.info(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {SAVE_PATH}")

    logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    import pydicom  # ‚Üê –ò–ú–ü–û–†–¢ –î–õ–Ø dicom_loader.py
    train_autoencoder()
