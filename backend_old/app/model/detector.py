# backend/model/detector.py
import torch
import torch.nn as nn
import numpy as np
import logging
import os
from pathlib import Path
import time
from typing import Optional, Tuple

from ..dataloader.dicom_loader import load_slices_from_zip

logger = logging.getLogger(__name__)


class StudyPathologyDetector:
    def __init__(self, model_path: str, hu_range: Tuple[int, int] = (-1000, 400)):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")

        self.hu_min, self.hu_max = hu_range
        self.model = self._load_model(model_path)
        self.model.eval()

    def _load_model(self, model_path: str):
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        try:
            model = torch.load(model_path, map_location=self.device)
            if isinstance(model, nn.Module):
                model.to(self.device)
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}")
                return model
            else:
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —ç—Ç–æ state_dict
                from .autoencoder_2d import Autoencoder2D  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—É—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω
                model = Autoencoder2D()
                model.load_state_dict(torch.load(model_path, map_location=self.device))
                model.to(self.device)
                model.eval()
                logger.info(f"‚úÖ State dict –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ {self.device}")
                return model
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def predict_study(self, zip_path: str) -> dict:
        result = {
            "filename": Path(zip_path).name,
            "processing_status": "Success",
            "error_detail": None,
            "probability_of_pathology": None,
            "study_uid": "UNKNOWN",
            "series_uid": "UNKNOWN",
            "processing_time_sec": 0.0
        }

        start_time = time.time()

        try:
            slices, study_uid, series_uid = load_slices_from_zip(zip_path, self.hu_min, self.hu_max)
            result["study_uid"] = study_uid
            result["series_uid"] = series_uid

            if len(slices) == 0:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –≤–∞–ª–∏–¥–Ω–æ–≥–æ DICOM-—Å—Ä–µ–∑–∞.")

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
            slices_tensor = torch.tensor(slices, dtype=torch.float32).unsqueeze(1).to(self.device)  # [N, 1, 256, 256]

            with torch.no_grad():
                reconstructed = self.model(slices_tensor)
                # –í—ã—á–∏—Å–ª—è–µ–º MSE –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ä–µ–∑–∞
                mse_per_slice = torch.mean((slices_tensor - reconstructed) ** 2, dim=[1, 2, 3]).cpu().numpy()
                # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –≤—Å–µ–º —Å—Ä–µ–∑–∞–º
                avg_mse = float(np.mean(mse_per_slice))
                # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —á–µ–º –≤—ã—à–µ MSE ‚Äî —Ç–µ–º –≤—ã—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–∞—Ç–æ–ª–æ–≥–∏–∏
                probability_of_pathology = min(max(avg_mse * 10, 0.0), 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ [0,1]

            result["probability_of_pathology"] = round(probability_of_pathology, 4)

        except Exception as e:
            result["processing_status"] = "Failure"
            result["error_detail"] = str(e)
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {zip_path}: {e}")

        result["processing_time_sec"] = round(time.time() - start_time, 2)
        return result
